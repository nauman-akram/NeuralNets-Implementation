{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZZB5Jd0K9d2"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h2><span style=\"color:green\"> Notebook for RNN, LSTM </span><h2>\n",
    "</div>\n",
    "    \n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhLr4lNpYPH3"
   },
   "source": [
    "## Recurrent Neural Network(RNN)\n",
    "**Recurrent Neural Networks(RNNs)** are a type of neural network where the **output from previous step is fed as input to the current step.** RNNs are used to tackle problems that requires knowledge from the past to make a prediction such as predicting next word in a sentence. RNN does this by maintaing a \"memory\" through a vector called **Hidden State**.\n",
    "\n",
    " At each time step $t$, an instance of a sequence $x_t\\in\\mathbb{R}^D$ and previous hidden state $h_{t-1}\\in\\mathbb{R}^H$  are passed to RNN. Using these two inputs, hidden state $h_t$ gets updated. The learnable parameters of the RNN are $(W_x\\in\\mathbb{R}^{H\\times D}, W_h\\in\\mathbb{R}^{H\\times H},b\\in\\mathbb{R}^{H} )$  input-to-hidden matrix , a hidden-to-hidden matrix  and a bias vector respectively.\n",
    "\n",
    "$$ h_t = tanh(W_{x}x_t + W_{h}h_{_{t-1}}+b) $$\n",
    "\n",
    "\n",
    "![RNN_folded_unfolded.png](attachment:RNN_folded_unfolded.png)\n",
    "<center>A folded (left) and un-folded (right) version of an RNN. <b>A</b> is feed forward neural network followed by an activation function. </center> \n",
    "\n",
    "<center> <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" title=\"colah's blog\">\n",
    "Image Source</a></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AcpBsi6AxzK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMmGw3sVK9eC"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h1><span style=\"color:green\"> One Fully-Connected Layer using nn.Linear  </span></h1>\n",
    "</div>\n",
    "\n",
    "Input row-vector is $x=[1,2,3]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "2bPoI91eK9eE",
    "outputId": "e41a20d0-5ecd-458f-b1cb-e76830ca6018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Input        :  1\n",
      "Dimension of Output       :  1\n",
      "Dimension of Weights Matrix:  2\n",
      "Weights Matrix shape:  torch.Size([10, 3])\n",
      "Dimension of Bias Vector  :  1\n",
      "Dimension Vector shape:  torch.Size([10])\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Weights Matrix of Fully-Connected Layer:\n",
      " Parameter containing:\n",
      "tensor([[-0.3022,  0.1795, -0.2554],\n",
      "        [-0.2759,  0.0609,  0.5240],\n",
      "        [-0.3625,  0.2213, -0.2127],\n",
      "        [ 0.4499,  0.2692, -0.0484],\n",
      "        [-0.4163,  0.5276, -0.4244],\n",
      "        [-0.3087, -0.4043, -0.3142],\n",
      "        [-0.3976,  0.2231,  0.0776],\n",
      "        [-0.4889,  0.0852,  0.1825],\n",
      "        [ 0.2134,  0.4461,  0.1765],\n",
      "        [-0.5164, -0.1690, -0.3482]], requires_grad=True)\n",
      "\n",
      "\n",
      "\n",
      "Bias Vector of Fully-Connected Layer:\n",
      " Parameter containing:\n",
      "tensor([-0.0390,  0.3639, -0.1948,  0.5256,  0.2918, -0.3366, -0.2461,  0.5035,\n",
      "         0.2364,  0.4523], requires_grad=True)\n",
      "\n",
      "\n",
      "\n",
      "Output:\n",
      " tensor([-0.7484,  1.7819, -0.7528,  1.3688, -0.3423, -2.3963,  0.0353,  0.7325,\n",
      "         1.8715, -1.4468], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x= [1,2,3]\n",
    "\n",
    "fc_layer = nn.Linear(len(x), 10, bias=True)\n",
    "tensor_input = torch.FloatTensor(x)\n",
    "output = fc_layer(tensor_input)\n",
    "\n",
    "print('Dimension of Input        : ' , tensor_input.dim())\n",
    "print('Dimension of Output       : ' , output.dim())\n",
    "print('Dimension of Weights Matrix: ' , fc_layer.weight.dim())\n",
    "print('Weights Matrix shape: ' , fc_layer.weight.shape)\n",
    "print('Dimension of Bias Vector  : ' , fc_layer.bias.dim())\n",
    "print('Dimension Vector shape: ' , fc_layer.bias.shape)\n",
    "\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "print('Weights Matrix of Fully-Connected Layer:\\n', fc_layer.weight)\n",
    "print('\\n\\n\\nBias Vector of Fully-Connected Layer:\\n',  fc_layer.bias)\n",
    "print('\\n\\n\\nOutput:\\n', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2I3prjokdncH"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h1><span style=\"color:green\"> A Single-layer RNN  </span></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P3RyHNVPdncN"
   },
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, hidden_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        \n",
    "        # Initialize W_x and W_h \n",
    "        # Bias terms are included in nn.Linear, so no need to initialize separate bias vector\n",
    "\n",
    "        self.W_x = nn.Linear(input_dim, hidden_dim) \n",
    "        self.W_h = nn.Linear(hidden_dim, hidden_dim) \n",
    "\n",
    "\n",
    "\n",
    "    def rnn_step(self, inp, hidden):\n",
    "        \n",
    "        \"\"\" Implementation of Single-layer RNN ONE Time Step\n",
    "            \n",
    "            Args:\n",
    "            \n",
    "                  inp   : input of shape( batch_size, input_dim)\n",
    "                  hidden: previous hiedden state h_(t-1)\n",
    "            \n",
    "            \n",
    "            Returns:\n",
    "                     h_t : updated hidden state after ONE time step \n",
    "            \"\"\"\n",
    "\n",
    "        \n",
    "        prev_h = hidden\n",
    "        h_t = None\n",
    "                \n",
    "        # TODO: Implement one time step and update h\n",
    "        ### tanh(W_xt + W_ht-1 + b )\n",
    "\n",
    "\n",
    "        h_t = torch.tanh(self.W_x(inp) + self.W_h(prev_h)) \n",
    "\n",
    "        return h_t\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "        # Input should be of shape(seq_dim, batch_size, input_dim)\n",
    "\n",
    "        seq_dim, batch_size , _ = inp.shape\n",
    "\n",
    "        \n",
    "        # Initialize hidden state with zeros and shape(batch_size, hidden_dim)\n",
    "        # In case of batch gradient descent we have to maintain hidden vector \n",
    "        # for each training example in the batch\n",
    "        \n",
    "        h = torch.zeros(batch_size,self.hidden_dim)\n",
    "\n",
    "        \n",
    "        # Loop through the whole sequence and update h_t at every time step\n",
    "        for x in inp:\n",
    "            # x is of shape (batch_size, input_dim)\n",
    "            h = self.rnn_step(x , h)\n",
    "        \n",
    "        return h \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtFFRIeXK9eb"
   },
   "source": [
    "#### Output of RNN after T time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWUBu8aofd9J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters in network:-\n",
      "W_x.weight -> torch.Size([100, 28])\n",
      "W_x.bias -> torch.Size([100])\n",
      "W_h.weight -> torch.Size([100, 100])\n",
      "W_h.bias -> torch.Size([100])\n",
      "------------------------------\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# Testing RNN: This code should run without any error\n",
    "\n",
    "x = torch.randn(28, 1, 28) # (Seq_dim, batch_dim, inp_dim)\n",
    "\n",
    "rnn = SimpleRNN(28, 100)\n",
    "\n",
    "# Dimension of network parameters\n",
    "print(\"parameters in network:-\")\n",
    "for name,p in rnn.named_parameters():\n",
    "    print(name,\"->\" ,p.shape)\n",
    "print(\"----------\"*3)\n",
    "    \n",
    "h_last_t = rnn(x)\n",
    "print(h_last_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCHZo4hX_KGF"
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# LSTM\n",
    "If you read recent papers, you'll see that many people use a variant on the vanilla RNN called Long-Short Term Memory (LSTM) RNNs. Vanilla RNNs can be tough to train on long sequences because it suffers from vanishing/exploding gradient problem due to repeated matrix multiplication. LSTMs solve this problem by replacing the simple update rule of the vanilla RNN with a gating mechanism as follows.\n",
    "\n",
    "\n",
    "Similar to the vanilla RNN, at each time step we receive an input $x_t\\in\\mathbb{R}^D$ and the previous hidden state $h_{t-1}\\in\\mathbb{R}^H$; the LSTM also maintains an $H$-dimensional *cell state*, so we also receive the previous cell state $c_{t-1}\\in\\mathbb{R}^H$. The learnable parameters of the LSTM are an *input-to-hidden* matrix $W_x\\in\\mathbb{R}^{4H\\times D}$, a *hidden-to-hidden* matrix $W_h\\in\\mathbb{R}^{4H\\times H}$ and a *bias vector* $b\\in\\mathbb{R}^{4H}$.\n",
    "\n",
    "**Points to be noted**\n",
    "\n",
    "* *Cell State* is the internal state of LSTM. It provides a path for the flow of gradient which does not contain matrix multiplication to reduce the chances of vanishing/exploding gradient.\n",
    "\n",
    "* *Hidden State* is the output of the LSTM\n",
    "\n",
    "![lstm.png](attachment:lstm.png)\n",
    "<center> <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" title=\"colah's blog\">\n",
    "Image Source</a></center>\n",
    "\n",
    "At each time step:\n",
    "\n",
    "**1.** An *activation vector* $a\\in\\mathbb{R}^{4H}$ is computed as $a=W_xx_t + W_hh_{t-1}+b$.\n",
    "\n",
    "**2.** Activation vector is partitioned into four vectors $a_i,a_f,a_o,a_c\\in\\mathbb{R}^H$ where $a_i$ consists of the first $H$ elements of $a$, $a_f$ is the next $H$ elements of $a$ and so on. \n",
    "\n",
    "**3.** We then compute the *input gate* $(i\\in\\mathbb{R}^H)$, *forget gate* $(f\\in\\mathbb{R}^H)$, *output gate* $(o\\in\\mathbb{R}^H)$ and *new candidate for $c_t$* $(\\tilde{c_t}\\in\\mathbb{R}^H)$ as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "i = \\sigma(a_i) \\hspace{2pc}\n",
    "f = \\sigma(a_f) \\hspace{2pc}\n",
    "o = \\sigma(a_o) \\hspace{2pc}\n",
    "\\tilde{c_t} = \\tanh(a_c)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is the sigmoid function and $\\tanh$ is the hyperbolic tangent, both applied element-wise.\n",
    "\n",
    "\n",
    "  * *new candidate vector* ($\\tilde{c_t}$) provides candidate values for new cell state ($c_t$)\n",
    "  \n",
    "  * *input gate* ($i$) determines the positions where data should be injected from  $\\tilde{c_t}$ to new cell state ($c_t$)\n",
    "\n",
    "  * *forget gate* ($f$) removes the useless data from previous cell state $c_{t-1}$\n",
    "\n",
    "  * *output gate* ($o$) determines the data to pass from current cell state $c_t$ to current hidden state $h_t$\n",
    "  \n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "**4.** Finally, we update the next cell state $c_t$ and next hidden state $h_t$ as follows\n",
    "\n",
    "$$\n",
    "c_{t} = f\\odot c_{t-1} + i\\odot \\tilde{c_t} \\hspace{4pc}\n",
    "h_t = o\\odot\\tanh(c_t)\n",
    "$$\n",
    "\n",
    "where $\\odot$ is the element-wise (Hadamard) product of vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-PABcjOAx0u"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h1><span style=\"color:green\"> A Single-layer LSTM  </span></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Cf6ozWaC-2g"
   },
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_dim, hidden_dim):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.input_dim  = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        \n",
    "        #TODO: Initialize W_x and W_h\n",
    "        # Bias terms are included in nn.Linear, so no need to initialize separate bias vector\n",
    "        \n",
    "        self.W_x = nn.Linear(input_dim, hidden_dim*4, bias=True)\n",
    "        self.W_h = nn.Linear(hidden_dim, hidden_dim*4, bias=True)\n",
    "\n",
    "\n",
    "\n",
    "    def lstm_step(self, inp, prev_hidden_cell):\n",
    "        \"\"\" Implementation of Single-layer LSTM ONE Time Step\n",
    "            \n",
    "            Args:\n",
    "                    inp      : input of shape(batch_size, input_dim)\n",
    "             prev_hidden_cell: tuple (previous_hidden_state, previous_cell_state)\n",
    "            \n",
    "            \n",
    "            Returns:\n",
    "                    Updated hidden state and cell state \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        \n",
    "        h_prev , c_prev = prev_hidden_cell\n",
    "        \n",
    "        \n",
    "        # The activation vector\n",
    "        activation = torch.tanh(self.W_x(inp) + self.W_h(h_prev))\n",
    "        \n",
    "        \n",
    "        # The activation is split into four parts\n",
    "        ai, af, ac, ao = activation.chunk(4, 1)\n",
    "\n",
    "        \n",
    "        updated_h, updated_c = None, None\n",
    "      \n",
    "    \n",
    "        # TODO: Implement the gates of lstm and update hidden state and cell state\n",
    "\n",
    "        in_gate     = torch.sigmoid(ai)\n",
    "        forget_gate = torch.sigmoid(af)\n",
    "        cell_gate   = torch.sigmoid(ac)\n",
    "        out_gate    = torch.tanh(ao)\n",
    "\n",
    "        \n",
    "        updated_c  = forget_gate*c_prev + in_gate*cell_gate\n",
    "        updated_h  = out_gate * torch.tanh(updated_c)\n",
    "        \n",
    "\n",
    "\n",
    "        return updated_h, updated_c\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "        \n",
    "        # input shape (seq_dim, batch_size, input_dim)\n",
    "        seq_dim, batch_size, _ = inp.shape\n",
    "        # TODO: initialize hidden and cell state and loop through sequence\n",
    "\n",
    "        # Initialize hidden state with zeros (batch_size, hidden_dim)\n",
    "        h = torch.zeros(batch_size, self.hidden_dim)\n",
    "        \n",
    "        # Initialize cell state with zeros (batch_size, hidden_dim)\n",
    "        c = torch.zeros(batch_size, self.hidden_dim)\n",
    "        \n",
    "        \n",
    "        # Loop through the whole sequence and update h_t and c_t at every time step\n",
    "        for x in inp:\n",
    "            \n",
    "           # shape of x is (batch_size, input_dim )\n",
    "        \n",
    "           h, c = self.lstm_step( x, (h, c) )\n",
    "        \n",
    "        return h \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8aoOVqkHEpX"
   },
   "source": [
    "#### Output of LSTM Cell after T time steps\n",
    "The final updated hidden state is the output of LSTM. After filtering the data through gates, the final hidden state can provide us with the relevant indormation for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfKB5rpg7yN6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing LSTM: The code should run with any erros\n",
    "\n",
    "#test input of shape(Sequence_len, Batch_size , Input_dim)\n",
    "x = torch.randn(28, 1 ,28)\n",
    "\n",
    "m = SimpleLSTM(28, 100)\n",
    "\n",
    "out = m(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "9-K_Hi3oAxzG"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h1><span style=\"color:orange\"> Image Classification with LSTM  </span></h1>\n",
    "</div>\n",
    "\n",
    "In this section, you  will use an LSTM network for MNIST image classification. We will use **many-to-one** scenario for this task. Refer to following figure to understand *many-to-one* LSTM.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "![lstm_shapes.png](attachment:lstm_shapes.png)\n",
    "<center> <a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\" title=\"Andrej Karpathy's blog\">\n",
    "Image Source</a></center>\n",
    "\n",
    "\n",
    "### Loading MNIST Train Dataset\n",
    "MNIST contains 70,000 images of handwritten digits: 60,000 for training and 10,000 for testing. The images are grayscale, 28x28 pixels, and centered to reduce preprocessing and get started quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lqoBq5UtAxzi"
   },
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0Pc-hQ7Axzz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data   :  torch.Size([60000, 28, 28])\n",
      "Train Labels :  torch.Size([60000])\n",
      "Test Data    :  torch.Size([10000, 28, 28])\n",
      "Test Labels  :  torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print('Train Data   : ',train_dataset.data.size())\n",
    "print('Train Labels : ',train_dataset.targets.size())\n",
    "print('Test Data    : ',test_dataset.data.size())\n",
    "print('Test Labels  : ',test_dataset.targets.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2a-YTEreqLNn"
   },
   "source": [
    "### Make Dataset Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x712Bsl4qLNp"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4eWyFr9LMtXF"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h1><span style=\"color:green\"> Plot Images  </span></h1>\n",
    "</div>\n",
    "\n",
    "Plot 4 random images using plt.imshow  and cmap = 'gray' in a 2x2 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ShahgdXHxwZ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAANTklEQVR4nO3deWwV1RfA8WFR2dxYDKCsCRpCCBEwmhiBCIJoGllciKBY/sAtEQIxggWjxSiSQECjJMQVhBrFEDQFQmURImKDgH9Q9xKk8AcVa6HSFkH945ff4Z6bzuvweO/1zLzv569zPfPm3dIcZ27vzL2t/v333wCAPa1bugMAmkZxAkZRnIBRFCdgFMUJGNW2mTx/ygWyr1VT/5ErJ2AUxQkYRXECRlGcgFEUJ2AUxQkY1dxUSqhWrZr86y9yrLkXF/g92ZDOCyZcOQGjKE7AKIoTMIriBIyiOAGjKE7AKIoTMIriBIyiOAGjKE7AKIoTMIriBIyiOAGjKE7AKIoTMIriBIyiOAGj0l4JwbIPPvhA4mnTpqlcUVGRxIsXL85ZnxDdiBEjVPull16SeNSoUSr3zz//SHzkyBGVGzt2rMS//PJLBnuYG1w5AaMoTsCoVs0sPBSatLxw1Pvvvy+xf1vb2NgocceOHXPVpayJ6wJf7du3V+358+dL/NRTT6ncNddcI7H/86T6+Q8fPizx8OHDVa62tjZ6ZzOgmd8Te6UAcUJxAkZRnIBRiZxKSeWKK66QeOjQoSq3f//+XHcnr7j/9q+//rrKFRYWRjrHl19+qdr+tIurX79+Et90000qV15eHun7WhJXTsAoihMwKpG3tRUVFZGOmzx5smpzW5tds2bNkjjVbWxlZaVqP/rooxJ/++23Kufe1rpTaEEQBD169JDY/11zWwsgbRQnYBTFCRiVyDHn2rVrJX7llVdCj+vbt69qt2174Z/j3LlzGe9XvuvatWuk4/xplr1794Ye607P1NXVhR735JNPqna3bt0knjFjRqR+5RpXTsAoihMwKpG3tVFNmTJFtZ944gmJT58+nevuJJ77Rkmqt2X27dsXmnvooYdUe+HChRLfeOONoZ/z30AaOXJk6LFWcOUEjKI4AaMoTsCovB5zIreqq6slTrUywJo1a1R7z549EvsrW7jnaW5VCFdxcXHkY1sKV07AKIoTMCqRC3x16NBB4g0bNqjc6NGjJfZ/ht69e0t87NixLPUus+K0wFf37t0lrqqqSuscqRb4OnnypMp9+OGHEm/ZskXlysrK0vr+dLHAF5AgFCdgFMUJGJXIqZQzZ85I/OOPP6qcO+b0LViwQOKnn35a5dw9OZAed0w4btw4lXNXMXBXMLgYs2fPVu2SkpK0zmMFV07AKIoTMCqRUymugoIC1XanVlL9Wd6dVgmCIDh+/HgWenfp4jSV4rruuutU212PdsCAAaGfS/U727hxo8r5i3q1JKZSgAShOAGjKE7AqEROpbj8vTXcMUvr1vr/TUyXZFebNm0kfuyxx1Qu1SoGrvr6etV29/mcMGGCyj377LMSL1u2TOXOnz8f6ftaEldOwCiKEzAq8VMp7dq1U+1du3ZJPGzYMJVjKiW7Bg8eLPGBAwdCj6upqVHtoqIiiTt16qRyzz//vMTu9vS+nj17qvaJEydSdzbDmEoBEoTiBIyiOAGjEj+V0tDQoNruG/D+mNN18803q7bVMWec+I/XhXnzzTdVe9WqVaHHDhkyROKpU6em1zGjuHICRlGcgFGJv61Nl/9GQ2lpaQv1JL6mT5+u2n369JHYn1p45513JH7ttdey27GY4MoJGEVxAkZRnIBRjDmRNe7W7s1Zv369xP6bJ/mKKydgFMUJGMVtLbLG3+rdfbn97NmzKue3wxQWFqq2vyWga//+/RL/9ddfkc5vCVdOwCiKEzCK4gSMyrsx59q1ayWeN29eC/Yk+R5//HHVdhdQO3TokMq5C7Fde+21Kjdp0iSJ/TdU3McA6+rqVO7ll1+WmDEngIyhOAGj8u62tqKiQuJTp06p3JVXXpnr7uSt/v37q7a7Lby/BeCgQYNCz+PeyvrTLFFf7raKKydgFMUJGEVxAkbl3ZjTtWTJEtVetGhRC/Ukmfypqvfee09if3HoMWPGRDqnv2Cbu9pC3MeYPq6cgFEUJ2BUXt/W7ty5U7UbGxtbpiMJtXr1atXevXu3xJ999pnKDRw4MPQ8K1eulLi4uFjlqqurL6WLpnHlBIyiOAGjKE7AqMTvz5l0cdqfM5+xPyeQIBQnYBTFCRhFcQJGUZyAURQnYBTFCRhFcQJGUZyAUWk/IQQgY3hCCIgTihMwiuIEjKI4AaMoTsAoihMwiuIEjEp79T3esLeBlRDiobnfU1O4cgJGUZyAURQnYBTFCRhFcQJGUZyAURQnYBTFCRhFcQJG5fX+nLBp9OjRql1WViZxeXm5yt1+++0Snz9/PrsdyzGunIBRFCdgFMUJGMX+nDGXlLdSOnbsKPGhQ4dUrlevXhL7P0+HDh0kbmhoyFLvLh37cwIJQnECRuXdVEqnTp0kdv8MHwRBMHLkSInvuusulRs2bJjE/q2Ve8uyefNmlbv33nvT72wecX8X7m2s77vvvlPtc+fOZa1PLY0rJ2AUxQkYRXECRiVyzNm+fXuJn3vuOZWbO3euxO6f4YNAjyX9P327bT9XU1MjcWlpaRo9zj+XX365ar/wwguRPvfuu++qNmNOADlHcQJGJeIJIXcKJAj0LdKoUaMin+fXX3+V+PTp0yr3xhtvhH7uiy++kLiqqiry92VCXJ8Quvvuu1U71XCgtrZW4s6dO2etT9nEE0JAglCcgFEUJ2BUbKdS3LHkxx9/rHJdunSR+I8//lC53377TeKlS5eq3Lp16zLYQ/guu+wyiefPnx/5c8uWLctGd8zjygkYRXECRsV2KmXTpk0Sjxs3TuV+//13iR944AGV27VrV3Y7lmNxmkoZPHiwxAcPHgw9rrGxUbV79uwp8Z9//hn5+7p37y7xfffdp3I7duyQ+Keffop8znQxlQIkCMUJGEVxAkbFZirlqquuUu2uXbuGHvv2229LnLQxZpzNmTMn0nH+o3ypxpnu9MyKFStUrrCwUGL/LZj6+nqJhw8frnI//PBDpH5mG1dOwCiKEzAqNre17lM/QRAE119/feixn3zySba7gwj69u2r2pMmTQo91p0+efHFF0OPa9OmjWrv3LlT4ttuuy1y39wX8t1F3yzhygkYRXECRlGcgFGxGXMePnxYtd3Fhd3HtIIgCBYvXizxgw8+qHKnTp3KQu/QlEGDBql2qrHd999/L7G/V4rrq6++Uu1bbrklzd7Zx5UTMIriBIyKzW3txXD3Ofn0009Vzn074cyZMznrUz5avny5aqd6Q8b9PfnTJe5L8LfeeqvKuW97nDx5UuXcbQXbtWsXoce2cOUEjKI4AaMoTsCo2K6EMGDAAIndRZ2DIAhuuOGG0M+5b6n4KyicPXs2Q73LHWsrIbj7mH7zzTehfTl+/LjK9enTR2L/sb+ff/65yXMEQRBUV1dLvHDhQpV76623Qj934sQJid0VGoJAr6SRKayEACQIxQkYFdupFPdW584771S5bdu2Sdy7d2+Vc/dV2b59u8q5+3fU1dVlpJ/5pnXrC/+/T3VL7d/mudMnxcXFkb/PfbF+yZIlKpfq+5955hmJs3EbmwlcOQGjKE7AKIoTMCq2UympuNMsW7ZsUTn/z/QudwvzyZMnq5w7PrX02J+1qZSZM2dKvHLlytDj/NyGDRsk3rp1a+jn/J+nuZ///3bv3q3a999/v8S5GHMylQIkCMUJGBXbqZRU3GkWf3vzWbNmSey/iO2uhbtx40aV+/zzzyV+5JFHVM7foj6f+fuchPn7779Ve8GCBRnvi/vS9sSJE1WupqYm49+XaVw5AaMoTsAoihMwKpFTKVENHDhQtUtKSiT231RwffTRR6o9derUzHbsIlibSnEX3Nq7d2/ocbW1tap99dVXRzp/qqmUiooKlRs/frzEVVVVkc6fLUylAAlCcQJG5fVtra9t2wszS+vXr1e5goICif2pkzFjxki8b9++LPWuadZua3v16iXx119/rXI9evS45PM3NDSo9ubNmyWePXu2yrX0rayL21ogQShOwCiKEzAqEY/v+VMZ5eXlEruP8jXHfSvlyJEjocdFfRMiHx09elTihx9+WOU2bdoksbs/ps//93UfnSwqKlI5f/okSbhyAkZRnIBRsZ1KGTp0qMTu1uNBEAQjRoyQ+ODBg6Hn8J8QctdcXbp0qcq5b6z453Q/l2vWplJS6d+/v8QrVqxQuXvuuUfi+vp6lbO6LfzFYCoFSBCKEzCK4gSMiu1Uirv3ohsHgd6D0x2bBoEeH/orIXTp0kVif4zgblc/b968NHqMyspKiadPn65y7kJsSRhjZgJXTsAoihMwKrZTKXfccYfE/lRKutyfqbS0VOUKCwsltrS3RpymUvIZUylAglCcgFEUJ2BUbMec7n6Or776qsrNnTs39HPuSgVlZWUq557H34LeXwTZCsac8cCYE0gQihMwKra3tfgfbmvjgdtaIEEoTsAoihMwiuIEjKI4AaMoTsAoihMwiuIEjKI4AaMoTsCotB/fA5AxPL4HxAnFCRhFcQJGUZyAURQnYBTFCRjV3F4pvEYPtBCunIBRFCdgFMUJGEVxAkZRnIBRFCdg1H9KXq7/5FV74QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Plot MNIST Images in 2x2 grid\n",
    "def show_imgs(inp):\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(inp)\n",
    "\n",
    "\n",
    "imgs, labels = next(iter(train_loader))\n",
    "\n",
    "show_imgs(torchvision.utils.make_grid(imgs[:4], nrow=2, pad_value=1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T3vwmkEAK9f-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjpEXu4gK9gF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RFru-N5PK9gL"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h1><span style=\"color:green\"> LSTM network for MNIST image Classification  </span></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HMouA8O9p93"
   },
   "source": [
    "### Initialize an LSTM Model Using Pytorch's nn.LSTM() Class\n",
    "Create an  LSTM model for classification of MNIST images. Follow the structure given below;\n",
    "\n",
    "1. One LSTM Cell\n",
    "2. One Linear Fully-Connected Layer\n",
    "\n",
    "\n",
    "Read Pytorch [documentation]( https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM) to learn about **nn.LSTM()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XDzRz-IPAx0w"
   },
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        \n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        \n",
    "        # Hidden dimensions: Number of features in hidden/cell state\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Number of LSTM cells/layers \n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        \n",
    "        \n",
    "        # Declaring attributes of model for LSTM cell and read-out linear fully-connected layer\n",
    "        self.lstm = None\n",
    "        self.fc   = None\n",
    "\n",
    "        \n",
    "        \n",
    "        # TODO: Intialize LSTM and linear layer\n",
    "             \n",
    "        \n",
    "        # Initialize LSTM Cell/s\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim,  batch_first=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Readout fully-connected layer. It takes hidden state from last time step and converts this hidden state to logits\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)                                     \n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Assuming batch_first=True\n",
    "        # x       : input consists of a sequence or a batch of sequences.   shape: (batch, seq_len, features)\n",
    "        #         : batch = number of sequences in one batch ,      seq_len = number of time steps       ,  features= number of features in one part sequence at each time step\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Everytime when model is called, intial hidden state and cell state would be initialized with zeros\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)     # shape: (num_layers * num_directions, batch, hidden_size)\n",
    "        # Initialize cell state with zeros\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)     # shape: (num_layers * num_directions, batch, hidden_size)\n",
    "        \n",
    "        \n",
    "        # x       : input consists of a sequence of batch of sequences.   shape: (batch, seq_len, features)                         Assuming batch_first=True\n",
    "        # out     : tensor containing hidden states from all time steps.  shape: (batch, seq_len,  num_directions * hidden_size)    Assuming batch_first=True\n",
    "        # (hn,cn) : hidden state and cell state after last time-step.     shape: (num_layers * num_directions, batch, hidden_size)\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        \n",
    "        \n",
    "        # Take hidden state from last time step and convert it to logits using fully-connected layer\n",
    "        out = self.fc(out[:, -1,:]) \n",
    "        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RHofntvvAx06"
   },
   "source": [
    "### Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RK6PB1eFAx08"
   },
   "outputs": [],
   "source": [
    "input_dim  = 28      # Number of elements in each part of sequence. \n",
    "hidden_dim = 100     # Number of elements in hidden/cell state\n",
    "layer_dim  = 1       # Number of LSTM Cells\n",
    "output_dim = 10      # Number of classes,  There are 10 classes in MNIST dataset (Digits: 0,1,2,...9)\n",
    "\n",
    "\n",
    "\n",
    "model = LSTMModel( input_dim, hidden_dim, layer_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwuxsDpxAx1G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmJWpzK-Ax1R"
   },
   "source": [
    "### Instantiate Loss Class\n",
    "We are going to use **Cross Entropy Loss** for this classifcation problem.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVX2NLKjAx1T"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n25l-VXfAx1f"
   },
   "source": [
    "### Instantiate Optimizer Class\n",
    "\n",
    "\n",
    "- Simplified equation\n",
    "    - $ \\boldsymbol{\\theta} $ = $\\boldsymbol{\\theta} - \\eta \\cdot \\nabla_{\\boldsymbol{\\theta}} $\n",
    "        - $ \\boldsymbol{\\theta} $: parameters (learnable variables/parameters)\n",
    "        - $\\eta $: learning rate (how fast we want to learn)\n",
    "        - $\\nabla_{\\boldsymbol{\\theta}}$: parameters' gradients\n",
    "- Even simplier equation\n",
    "    - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    - **At every iteration, we update our model's parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjbo0uYXAx1h"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hThFQTpWAx1p"
   },
   "source": [
    "### Parameters In-Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWziDDg7Ax1s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70Vc8-KWAx13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 28])\n",
      "torch.Size([400, 100])\n",
      "torch.Size([400])\n",
      "torch.Size([400])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F9qisKEzAx2C"
   },
   "source": [
    "### Understanding LSTM Training\n",
    "\n",
    "Firstly lets see how image passes through LSTM and loss is calculate.\n",
    "\n",
    "1. Firstly, we have converted 28x28 image into sequence of 28 1x28 image strips.\n",
    "2. At each time step, we feed LSTM 1x28 image strip and update hidden state and cell state.\n",
    "3. After passing all the 28 1x28 sequence of image parts, we take the final hidden state and pass it as input to a fully connected layer.\n",
    "4. The fully-connected layer outpus, 10 logits(unnormalized scores) for iamge classes.\n",
    "5. We use softmax to normalize the scores and calculate Cross Entropy Loss\n",
    "\n",
    "In case of backward pass, gradient flows from final time step to initial time step of LSTM and gradients of parameters are added together.\n",
    "\n",
    "\n",
    "\n",
    "### Train Model\n",
    "- Process \n",
    "    1. Take one sequence or batch of sequences\n",
    "    2. Clear gradient buffers\n",
    "    3. Get output by forward-passing input through model/network\n",
    "    4. Compute **cross-entropy** loss using labels and output of network\n",
    "    5. Get gradients w.r.t. parameters\n",
    "    6. Update parameters using gradients\n",
    "        - `parameters = parameters - learning_rate * parameters_gradients`\n",
    "    7. REPEAT\n",
    "\n",
    "In this homework, we will feed an LSTM cell an entire MNIST image in the form of a sequence of 28 rows and then classify the image. Data can be viewed as a set of $N$ examples $\\{(\\mathbf{x_i},y_i)\\}_{i=1}^{N}$. In each pair $(\\mathbf{x_i},y_i)$, $\\mathbf{x_i} = \\langle \\mathbf{x_{i,1}}, \\mathbf{x_{i,2}},\\dots, \\mathbf{x_{i,28}}\\rangle$ is a sequence of 28 vectors, each of dimension $(1,28)$.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rzUK4MCyK9g4"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzUkcxPqAx2D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 2.2586429119110107. Accuracy: 18.17\n",
      "Iteration: 1000. Loss: 0.9691744446754456. Accuracy: 68.57\n",
      "Iteration: 1500. Loss: 0.44801756739616394. Accuracy: 86.61\n",
      "Iteration: 2000. Loss: 0.3086774945259094. Accuracy: 92.14\n",
      "Iteration: 2500. Loss: 0.17383822798728943. Accuracy: 94.45\n",
      "Iteration: 3000. Loss: 0.17661446332931519. Accuracy: 94.38\n"
     ]
    }
   ],
   "source": [
    "# Number of time steps or Number of constituents of one sequence\n",
    "seq_len = 28  \n",
    "\n",
    "\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        # Shape of images = (batch_size, num_channels, 28, 28)\n",
    "        # Shape of images = (batch_size, 1           , 28, 28)\n",
    "        \n",
    "        # Reshape batch of images into batch of sequences,    \n",
    "        inputs = images.view(-1, seq_len, input_dim)  # shape: (batch, seq_len, input_features)\n",
    "        \n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        \n",
    "        # Test Accuracy on Test Data\n",
    "        if iteration % 500 == 0:\n",
    "            with torch.no_grad():   #  We do not want to add following operations in computation graph.\n",
    "                \n",
    "                \n",
    "                correct = 0\n",
    "                total = 0\n",
    "\n",
    "\n",
    "                # Iterate through test dataset\n",
    "                for images, labels in test_loader:\n",
    "\n",
    "                    # Shape of images = (batch_size, num_channels, 28, 28)\n",
    "                    # Shape of images = (batch_size, 1           , 28, 28)\n",
    "                    \n",
    "                    # Reshape batch of images into batch of sequences\n",
    "                    inputs = images.view(-1, seq_len, input_dim)   # shape: (batch, seq_len, input_features)\n",
    "        \n",
    "        \n",
    "\n",
    "                    # Forward pass only to get logits/output\n",
    "                    outputs = model(inputs)\n",
    "\n",
    "                    # Get predictions from outputs\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                    \n",
    "                    # Total number of labels\n",
    "                    total += labels.size(0)\n",
    "\n",
    "                    \n",
    "                    # Total correct predictions\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "                accuracy = 100 * correct.item() / total\n",
    "\n",
    "                # Print Loss\n",
    "                print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iteration, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c7aKc1fdK9hJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etwNTm2fK9hQ"
   },
   "source": [
    "### Convert .IPYNB to .HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZLMp8W0K9hR",
    "outputId": "dfd77763-45d3-47c1-a9de-93521779cd1c"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "cwd = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "\n",
    "!jupyter nbconvert HW4_msds19041.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k9nBhs0_K9hY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW4_msds19041.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
